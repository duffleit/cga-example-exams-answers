## 1. Wie wirkt sich bei einem Soft Object das Erhöhen des Wertes von „magic“ aus?

Der Magic-Wert regelt die Interaktion eines Soft Objects mit seiner Umgebung. Ein höherer Magic-Wert führt zu einer größeren Interaktion mit seiner Umgebung (zB. anderen Soft Objects)

## 2. Was kann ich mit den Tangenten im Animationskurven-Editor von Blender beeinflussen?

Mithilfe der Tangenten können die Interpolationskurven, welche die Verändung einer Eigenschaften zwischen 2 Keyframes beschreiben, verändert werden.

## 3. Welche Nachteile hat Displacement mapping gegenüber Bump mapping?

Displacement mapping varändert im Gegensatz zu Bumpmapping die Geometrie des Objektes. Das Verschieben der Objekt-vertices ist aufwändiger. Werden je nach Eintstellung zusätzliche Polygone erzeugt, steigt der Speicherbedarf.

Anm.: In den Folien steht außerdem, dass mit Displacement mapping keine Hinterscheidungen möglich sind. Allerdings ist dies auch mit Bump mapping nicht möglich und daher ist es kein Nachteil von Displacement mapping gegenüber Bump mapping.

## 4. Womit kann ich am geeignetsten ein Billardspiel animieren?

Mithilfe einer physikalischen Simulation, da diese die Abprallwinkel und Geschwindigkeiten (siehe [Impulserhaltungssatz](https://de.wikipedia.org/wiki/Impulserhaltungssatz)) korrekt berechnet und somit der Großteil der Animation von der Simulationssoftware übernommen wird.

## 5. Wie funktioniert "Ambient Occlusion"?

Ambient Occulusion ist ein lokales Beleuchtungsmodell, welches sehr einfach zu implementieren, aber bei der Berechnung sehr zeit-intensiv ist. Pro Flächenelement werden Strahlen in den Himmel geschossen. Der ambiente Beleuchtungsanteil ist relativ zu der Anzahl der Strahlen, die kein Objekt getroffen haben. zB.: 4/6 Strahlen treffen kein Objekt => Helligkeit des Flächenelements ist 66% der ambienten Beleuchtung.

## 6. Wann versagt optical motion capture?

Optical motion capture versagt, wenn die am Körper angebrachten Anhaltspunkte verdeckt werden oder sich die Anhaltspunkte 2 verschiedener Körper überschneiden. zB bei Kämpfen

## 7. Womit kann ich beim Subdivision Modifier in Blender scharfe Kanten modellieren?

In Blender hat man dafür 3 Möglichkeiten:

a. Durch das Hinzufügen von mehr Vertices mithilfe von Edge Loops.
b. Gewichtete Kanten (Weighted Creases)
c. Mithilfe eines Edge Split-Modifiers und geschärften Kanten.

Quelle: [Blender Doku](https://de.wikibooks.org/wiki/Blender_Dokumentation:_Gesch%C3%A4rfte_Kanten_beim_Arbeiten_mit_Subdivision_Surfaces)

## 8. Wodurch kann ich in Blender ein UV-Parametrisierung zerlegen?

1. Objekt hinzufügen (z.B. Kugel)
2. Tab in Edit Mode
3. Mittellinie markieren (Alt + Rechtsklick auf die horizontale Linie)
4. Strg + e => ``Mark Seam``
5. ``a`` drücken um alle Edges zu markieren
6. ``u`` Unwrap
7. jetzt kann im UV Editor die Paramtrisierung auf ein Bild (Textur) vorgenommen werden.

Quelle: [Blender Doku](https://de.wikibooks.org/wiki/Blender_Dokumentation:_UV-Mapping)

## 9. Benötige ich für prozedurale Animation inverse Kinematik? (Begründung)

Nein. Bei einer prozeduralen Animation ist die Bewegung programmiert (zB Rollen eines Rades, Ticken einer Uhr), wohingegen inverse Kinematik dann hilfreich ist, wenn ein verkettetes Objekt bewegt werden soll, ohne dabei jedes Glied der Kette einzeln animieren zu müssen (zB Bewegung eines Armes durch Verändern der Position der Hand). Für die Programmierung einer Animation benötigt man daher keine inverse Kinematik.

## 10. Nachdem ich in Blender ein UV Mapping für ein Objekt definiert habe, was muss ich beim Material des Objekts anpassen?

Die Textur muss als Material gelinkt werden (Properties Window -> Material Tab -> Browse Material to be linked {Schaltflächen-Symbol ist dasselbe wie das Material-Symbol})

## 11. Wann tritt Aliasing beim Texture-Rendering auf? Genaue Bedingung geben!

Aliasing tritt auf, wenn mehr als 1 Texel auf 1 Pixel gemappt werden soll.

## 12. Was definiert die uv-Parametrisierung eines Objektes?

Die UV-Parametrisierung gibt an, welcher Texel auf einen pixel gemapped wird.
uv ist die Position auf der Textur(Bild) die auf den Pixel im Objekt gezeichnet wird.

## 13. Wie werden rigid bodies simuliert?

Rigid bodies können mit einer physikalischen Simulation simuliert werden. Je nachdem, wie die Kräfte auf den ``rigid body`` wirken, verursachen sie eine Beschleunigung und/oder Drehmoment.
Kollisionen werden dabei aus Komplexitätsgründen näherungsweise reibungslos berechnet.

## 14. Was ist der Hauptvorteil von Solid Texturing?

Solid textures sind 3D Texturen, aus welchen die zu texturierenden Objekte einfach "ausgeschnitten" werden können. Daher entfallen bei Solid Texturing alle Probleme, die normalerweise beim Mappen einer 2D Textur auf ein 3D Objekt entstehen.

## 15. Welche Eigenschaften eines Objekts können im Szenegraphen geändert werden?

## 16. Was ist "match moving" und wofür wird es benötigt?

Mithilfe von Matchmoving können virtuelle Objekte in reale Videoaufnahmen eingefügt werden. Die Bewegungen verschiedener Objekte in der Aufnahme werden verfolgt und aufgrund der Verschiebung wird die Position der virtuellen Objekte im Raum berechnet und der Bildwinkel der realen Kamera berechnet.

Damit kann zb ein Bild in einer Videoaufnahme durch ein anderes ersetzt werden.

## 17. Welche Effekte könne nur mit einem globalen Beleuchtungsmodell simuliert werden? Mindesten drei Antworten.

- Brechung
- Reflexionen
- Schatten

## 18. Wie modelliere ich am geeignetsten einen Wald?

Mit einem hierachischen Partikelsystem.

## 19. Worin unterscheidet sich anisotrope Reflexion von isotroper ("normaler") Reflexion?

Anisotrope Reflexion wird durch die Geometrie des reflektierenden Objektes hervorgerufen, während isotrope / normale Reflexion durch das Material bestimmt wird.
